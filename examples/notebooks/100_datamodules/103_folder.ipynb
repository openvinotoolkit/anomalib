{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `Folder` for Customs Datasets\n",
    "\n",
    "# Installing Anomalib\n",
    "\n",
    "The easiest way to install anomalib is to use pip. You can install it from the command line using the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anomalib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset Directory\n",
    "\n",
    "This cell is to ensure we change the directory to have access to the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# NOTE: Provide the path to the dataset root directory.\n",
    "#   If the datasets is not downloaded, it will be downloaded\n",
    "#   to this directory.\n",
    "dataset_root = Path.cwd().parent.parent / \"datasets\" / \"hazelnut_toy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Folder Dataset (for Custom Datasets) via API\n",
    "\n",
    "Here we show how one can utilize custom datasets to train anomalib models. A custom dataset in this model can be of the following types:\n",
    "\n",
    "- A dataset with good and bad images.\n",
    "- A dataset with good and bad images as well as mask ground-truths for pixel-wise evaluation.\n",
    "- A dataset with good and bad images that is already split into training and testing sets.\n",
    "\n",
    "To experiment this setting we provide a toy dataset that could be downloaded from the following [https://github.com/openvinotoolkit/anomalib/blob/main/docs/source/data/hazelnut_toy.zip](link). For the rest of the tutorial, we assume that the dataset is downloaded and extracted to `../datasets`, located in the `anomalib` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8: noqa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms.v2 import Resize\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "\n",
    "from anomalib.data import Folder, FolderDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "Similar to how we created the datamodules for existing benchmarking datasets in the previous tutorials, we can also create an Anomalib datamodule for our custom hazelnut dataset.\n",
    "\n",
    "In addition to the root folder of the dataset, we now also specify which folder contains the normal images, which folder contains the anomalous images, and which folder contains the ground truth masks for the anomalous images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_datamodule = Folder(\n",
    "    name=\"hazelnut_toy\",\n",
    "    root=dataset_root,\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"crack\",\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    ")\n",
    "folder_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "data = next(iter(folder_datamodule.train_data))\n",
    "print(data.image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "data = next(iter(folder_datamodule.test_data))\n",
    "print(data.image.shape, data.gt_mask.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference. We could visualize samples from the dataloaders as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = to_pil_image(data.image.clone())\n",
    "msk = to_pil_image(data.gt_mask.int() * 255).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Folder` data module offers much more flexibility cater all different sorts of needs. Please refer to the documentation for more details.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset\n",
    "\n",
    "As in earlier examples, we can also create a standalone PyTorch dataset instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderDataset??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some transforms that will be applied to the images using torchvision. Let's add a transform that resizes the \n",
    "input image to 256x256 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = Resize(image_size, antialias=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the dataset, we'll start with the training subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_train = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    ")\n",
    "print(len(folder_dataset_train))\n",
    "sample = folder_dataset_train[0]\n",
    "print(sample.image.shape, sample.image_path, sample.gt_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `train` split, the dataset contains 34 samples. These are the normal images that have been assigned to the training set, which have a corresponding ground truth label of `False`, indicating that the image does not contain an anomaly. \n",
    "\n",
    "Now let's have a look at the test set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Classification Test Set\n",
    "folder_dataset_test = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    ")\n",
    "print(len(folder_dataset_test))\n",
    "sample = folder_dataset_test[0]\n",
    "print(sample.image.shape, sample.image_path, sample.gt_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the Folder dataset for the segmentation task, where the dataset object returns image and ground-truth mask. To achieve this, we need to pass a folder of ground truth masks to the dataset. The mask folder should contain a ground truth pixel mask for every anomalous image in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Train Set\n",
    "folder_dataset_segmentation_train = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    ")\n",
    "print(len(folder_dataset_segmentation_train))\n",
    "sample = folder_dataset_segmentation_train[0]\n",
    "print(sample.image.shape, sample.gt_mask.shape, sample.image_path, sample.gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Test Set\n",
    "folder_dataset_segmentation_test = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    ")\n",
    "print(len(folder_dataset_segmentation_test))\n",
    "sample = folder_dataset_segmentation_test[0]\n",
    "print(sample.image.shape, sample.gt_mask.shape, sample.image_path, sample.gt_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = to_pil_image(data.image.clone())\n",
    "msk = to_pil_image(data.gt_mask.int() * 255).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
