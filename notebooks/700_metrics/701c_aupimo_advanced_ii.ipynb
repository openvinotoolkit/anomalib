{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUPIMO\n",
    "\n",
    "Advance use cases of the metric AUPIMO (pronounced \"a-u-pee-mo\").\n",
    "\n",
    "> For basic usage, please check the notebook [701a_aupimo.ipynb](./701a_aupimo.ipynb).\n",
    "\n",
    "Includes:\n",
    "- visualization of the PIMO curve\n",
    "- theoretical AUPIMO of a random classifier (\"baseline\")\n",
    "- understanding the x-axis (FPR) bounds\n",
    "- customizing the x-axis (FPR) bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is AUPIMO?\n",
    "\n",
    "The `Area Under the Per-Image Overlap [curve]` (AUPIMO) is a metric of recall (higher is better) designed for visual anomaly detection.\n",
    "\n",
    "Inspired by the [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and [PRO](https://link.springer.com/article/10.1007/s11263-020-01400-4) curves, \n",
    "\n",
    "> AUPIMO is the area under a curve of True Positive Rate (TPR or _recall_) as a function of False Positive Rate (FPR) restricted to a fixed range. \n",
    "\n",
    "But:\n",
    "- the TPR (Y-axis) is *per-image* (1 image = 1 curve/score);\n",
    "- the FPR (X-axis) considers the (average of) **normal** images only; \n",
    "- the FPR (X-axis) is in log scale and its range is [1e-5, 1e-4]\\* (harder detection task!).\n",
    "\n",
    "\\* The score (the area under the curve) is normalized to be in [0, 1].\n",
    "\n",
    "AUPIMO can be interpreted as\n",
    "\n",
    "> average segmentation recall in an image given that the model (nearly) does not yield false positives in normal images.\n",
    "\n",
    "References in the last cell.\n",
    "\n",
    "![AUROC vs. AUPRO vs. AUPIMO](./roc_pro_pimo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `anomalib` using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(jpcbertoldo): replace by `pip install anomalib` when AUPIMO is released  # noqa: TD003\n",
    "%pip install ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the directory to have access to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# NOTE: Provide the path to the dataset root directory.\n",
    "#   If the datasets is not downloaded, it will be downloaded\n",
    "#   to this directory.\n",
    "dataset_root = Path.cwd().parent.parent / \"datasets\" / \"MVTec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.ticker import FixedLocator, PercentFormatter\n",
    "from numpy import ndarray\n",
    "from scipy import stats\n",
    "from torch import Tensor\n",
    "\n",
    "from anomalib import TaskType\n",
    "from anomalib.data import MVTec\n",
    "from anomalib.data.utils import read_image\n",
    "from anomalib.engine import Engine\n",
    "from anomalib.metrics import AUPIMO, Evaluator\n",
    "from anomalib.models import Padim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "This part was covered in the notebook [701a_aupimo.ipynb](./701a_aupimo.ipynb), so we'll not discuss it here.\n",
    "\n",
    "It will train a model and evaluate it using AUPIMO.\n",
    "We will use dataset Leather from MVTec AD with `PaDiM` (performance is not the best, but it is fast to train).\n",
    "\n",
    "> See the notebooks below for more details on:\n",
    "> - datamodules: [100_datamodules](https://github.com/openvinotoolkit/anomalib/tree/main/notebooks/100_datamodules);\n",
    "> - models: [200_models](https://github.com/openvinotoolkit/anomalib/tree/main/notebooks/200_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "task = TaskType.SEGMENTATION\n",
    "datamodule = MVTec(\n",
    "    root=dataset_root,\n",
    "    category=\"leather\",\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    num_workers=8,\n",
    "    task=task,\n",
    ")\n",
    "evaluator = Evaluator(test_metrics=AUPIMO())\n",
    "model = Padim(\n",
    "    # only use one layer to speed it up\n",
    "    layers=[\"layer1\"],\n",
    "    n_features=64,\n",
    "    backbone=\"resnet18\",\n",
    "    pre_trained=True,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "engine = Engine(\n",
    "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
    "    devices=1,\n",
    "    logger=False,\n",
    ")\n",
    "engine.fit(datamodule=datamodule, model=model)\n",
    "# infer\n",
    "predictions = engine.predict(dataloaders=datamodule.test_dataloader(), model=model, return_predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AUPIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aupimo = AUPIMO(\n",
    "    # with `False` all the values are returned in a dataclass\n",
    "    return_average=False,\n",
    ")\n",
    "\n",
    "anomaly_maps = []\n",
    "masks = []\n",
    "labels = []\n",
    "image_paths = []\n",
    "for batch in predictions:\n",
    "    anomaly_maps.append(batch.anomaly_map.squeeze(dim=1))\n",
    "    masks.append(batch.gt_mask)\n",
    "    labels.append(batch.gt_label)\n",
    "    image_paths.append(batch.image_path)\n",
    "    aupimo.update(batch)\n",
    "\n",
    "# list[list[str]] -> list[str]\n",
    "image_paths = [item for sublist in image_paths for item in sublist]\n",
    "anomaly_maps = torch.cat(anomaly_maps, dim=0)\n",
    "masks = torch.cat(masks, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "# `pimo_result` has the PIMO curves of each image\n",
    "# `aupimo_result` has the AUPIMO values\n",
    "#     i.e. their Area Under the Curve (AUC)\n",
    "pimo_result, aupimo_result = aupimo.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics and score distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the normal images have `nan` values because\n",
    "# recall is not defined for them so we ignore them\n",
    "print(f\"MEAN\\n{aupimo_result.aupimos[labels == 1].mean().item()=}\")\n",
    "print(f\"OTHER STATISTICS\\n{stats.describe(aupimo_result.aupimos[labels == 1])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(aupimo_result.aupimos[labels == 1].numpy(), bins=np.linspace(0, 1, 11), edgecolor=\"black\")\n",
    "ax.set_ylabel(\"Count (number of images)\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel(\"AUPIMO [%]\")\n",
    "ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.grid()\n",
    "ax.set_title(\"AUPIMO distribution\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until here we just reproduded the notebook with the basic usage of AUPIMO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PIMO curve \n",
    "\n",
    "We'll select a bunch of images to visualize the PIMO curves.\n",
    "\n",
    "To make sure we have best and worst detection examples, we'll use the representative samples selected in the previous notebook ([701b_aupimo_advanced_i.ipynb](./701b_aupimo_advanced_i.ipynb)).\n",
    "\n",
    "> Note the FPR (X-axis) is the average (in-image) FPR of the normal images in the test set. We'll note it as `FPRn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representative samples (in terms of the AUPIMO value)\n",
    "# from lowest to highest AUPIMO score\n",
    "samples = [65, 7, 58, 63, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_pow10(value: float) -> str:\n",
    "    \"\"\"Format the power of 10.\"\"\"\n",
    "    return \"1\" if value == 1 else f\"$10^{{{int(np.log10(value))}}}$\"\n",
    "\n",
    "\n",
    "def plot_pimo_with_auc_zone(\n",
    "    ax: Axes,\n",
    "    tpr: ndarray,\n",
    "    fpr: ndarray,\n",
    "    lower_bound: float,\n",
    "    upper_bound: float,\n",
    "    fpr_in_auc: ndarray,\n",
    "    tpr_in_auc: ndarray,\n",
    ") -> None:\n",
    "    \"\"\"Helper function to plot the PIMO curve with the AUC zone.\"\"\"\n",
    "    # plot\n",
    "    ax.plot(fpr, tpr, linewidth=3.5)\n",
    "    ax.axvspan(lower_bound, upper_bound, color=\"magenta\", alpha=0.3, zorder=-1)\n",
    "    ax.fill_between(fpr_in_auc, tpr_in_auc, alpha=1, color=\"tab:purple\", zorder=1)\n",
    "\n",
    "    # config plots\n",
    "    ax.set_ylabel(\"TPR [%]\")\n",
    "    ax.yaxis.set_major_locator(FixedLocator(np.linspace(0, 1, 6)))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1, 0, symbol=\"\"))\n",
    "    ax.set_ylim(0, 1 + 3e-2)\n",
    "    ax.set_xlabel(\"FPRn\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.xaxis.set_major_locator(FixedLocator(np.logspace(-6, 0, 7)))\n",
    "    ax.xaxis.set_major_formatter(lambda x, _: fmt_pow10(x))\n",
    "    ax.set_xlim(1e-6 / (eps := (1 + 3e-1)), 1 * eps)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 5), layout=\"tight\")\n",
    "\n",
    "for ax, index in zip(axes.flatten(), samples, strict=False):\n",
    "    score = aupimo_result.aupimos[index].item()\n",
    "    tpr = pimo_result.per_image_tprs[index]\n",
    "    fpr = pimo_result.shared_fpr\n",
    "    lower_bound, upper_bound = aupimo.fpr_bounds\n",
    "    threshs_auc_mask = (pimo_result.thresholds > aupimo_result.thresh_lower_bound) & (\n",
    "        pimo_result.thresholds < aupimo_result.thresh_upper_bound\n",
    "    )\n",
    "    fpr_in_auc = fpr[threshs_auc_mask]\n",
    "    tpr_in_auc = tpr[threshs_auc_mask]\n",
    "\n",
    "    plot_pimo_with_auc_zone(ax, tpr, fpr, lower_bound, upper_bound, fpr_in_auc, tpr_in_auc)\n",
    "    ax.set_title(f\"Image {index} ({score:.0%} AUPIMO)\")\n",
    "\n",
    "axes[-1, -1].axis(\"off\")\n",
    "axes[-1, -1].text(\n",
    "    -0.08,\n",
    "    0,\n",
    "    \"\"\"\n",
    "FPRn: Avg. [in-image] False Positive Rate (FPR)\n",
    "      on normal images only ('n').\n",
    "\n",
    "TPR: [in-image] True Positive Rate (TPR),\n",
    "     or Recall.\n",
    "\n",
    "Integration zone in light pink, and area\n",
    "under the curve (AUC) in purple.\n",
    "\n",
    "This area is normalized by the range size\n",
    "so that AUPIMO is in [0, 1].\n",
    "\"\"\",\n",
    "    ha=\"left\",\n",
    "    va=\"bottom\",\n",
    "    fontsize=\"x-small\",\n",
    "    color=\"dimgray\",\n",
    "    font=\"monospace\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"PIMO curves\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaning of the FPRn bounds\n",
    "\n",
    "AUPIMOo only uses _normal images_ in the X-axis -- i.e. the $\\operatorname{FPRn}$.\n",
    "\n",
    "**Why?** \n",
    "\n",
    "Because the integration range is a validation\\* of \"usable operating thresholds\", so using $\\operatorname{FPRn}$ makes it unbiased (to the anomalies).\n",
    "\n",
    "> Recall that, in practice, a threshold is set to decide if a pixel/image is anomalous.\n",
    "> \n",
    "> This strategy was inspired on [AUPRO](https://link.springer.com/article/10.1007/s11263-020-01400-4).\n",
    "\n",
    "---\n",
    "\n",
    "**Definition 1**: Average FPR on Normal Images ($\\operatorname{FPRn}$):\n",
    "\n",
    "$$\n",
    "    \\operatorname{FPRn} : t \\mapsto \\frac{1}{N} \\sum_{i=1}^{N} \\; \\times \\; \\operatorname{FPR}^{i}(t)\n",
    "$$\n",
    "\n",
    "where $i$ and $N$ are, respectively, the index and the number of normal images in the test set. Note that $\\operatorname{FPRn}$ is the empirical average of $\\operatorname{FPR}^{i}$, so \n",
    "\n",
    "$$\n",
    "    \\operatorname{FPRn} \\approx \\mathbb{E} \\left[ \\operatorname{FPR}^{i} \\right]\n",
    "$$\n",
    "\n",
    "**Defintion 2**: FPR of the $i$-th normal image ($\\operatorname{FPR}^{i}$): \n",
    "\n",
    "$$\n",
    "    \\operatorname{FPR}^{i} : t \\mapsto \\frac{\\text{Area of } \\mathbb{a}^{i} \\text{ above } t}{\\text{Area of } \\mathbb{a}^{i}}\n",
    "$$\n",
    "\n",
    "where $\\mathbb{a}^{i}$ is the anomaly score map of the $i$-th image.\n",
    "\n",
    "---\n",
    "\n",
    "No further ado, let's visualize this $\\operatorname{FPRn}$!\n",
    "\n",
    "> For more details on this topic, check our paper in the last cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the FPR of normal images ($\\operatorname{FPR}^{i}$)\n",
    "\n",
    "$\\operatorname{FPRn}$ is the average of $\\operatorname{FPR}^{i}$, so let's first visualize the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visalization of $FPR^i$\n",
    "#   since normal images do not have anomalous pixels\n",
    "#   their FPR actually correspond to the ratio of pixels\n",
    "#   (wrongly) classified as anomalous\n",
    "\n",
    "# we'll visualize 3 levels of FPR^(i) on some normal images\n",
    "FRP_levels = [1e-2, 1e-3, 1e-4]\n",
    "# technical detail: decreasing order of FPR --> increasing order of threshold\n",
    "\n",
    "\n",
    "def threshold_from_fpr(anomaly_map: Tensor, fpr_level: float | Tensor) -> float:\n",
    "    \"\"\"Find the threshold that corresponds to the given FPR level.\n",
    "\n",
    "    Args:\n",
    "        anomaly_map (torch.Tensor): Anomaly map, assumed to be from a normal image.\n",
    "        fpr_level (float): Desired FPR level.\n",
    "\n",
    "    Returns:\n",
    "        float: Threshold such that `(anomaly_map > threshold).mean() == fpr_level`.\n",
    "    \"\"\"\n",
    "    # make a dicothomic search\n",
    "    lower, upper = anomaly_map.min(), anomaly_map.max()  # initial bounds\n",
    "    middle = (lower + upper) / 2\n",
    "    fpr_level = torch.tensor(fpr_level)\n",
    "\n",
    "    def fpr(threshold: Tensor) -> Tensor:\n",
    "        return (anomaly_map > threshold).float().mean()\n",
    "\n",
    "    while not torch.isclose(fpr(middle), fpr_level, rtol=1e-2):\n",
    "        if torch.isclose(lower, upper, rtol=1e-3):\n",
    "            break\n",
    "        if fpr(middle) < fpr_level:\n",
    "            upper = middle\n",
    "        else:\n",
    "            lower = middle\n",
    "        middle = (lower + upper) / 2\n",
    "    return middle.item()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5), layout=\"constrained\")\n",
    "\n",
    "# select normal images with low and high mean anomaly scores\n",
    "avg_anom_score_per_image = anomaly_maps.mean(dim=(1, 2))\n",
    "# get the indices of the normal images sorted by their mean anomaly score\n",
    "argsort = avg_anom_score_per_image.sort().indices\n",
    "argsort = argsort[torch.isin(argsort, torch.where(labels == 0)[0])]\n",
    "# select first, median and last\n",
    "normal_images_selection = argsort[[0, len(argsort) // 2, -1]]\n",
    "\n",
    "# heatmaps will be normalized across *normal* images\n",
    "# so the range of thresholds have an exact mapping to the range of [0, 1] in FPRn\n",
    "# PS: it is not exactly true because we don't get a min-max, but a quantile-based normalization\n",
    "global_normal_vmin, global_normal_vmax = torch.quantile(anomaly_maps[labels == 0], torch.tensor([0.02, 0.98]))\n",
    "\n",
    "for ax, index in zip(axes, normal_images_selection, strict=False):\n",
    "    image = cv2.resize(read_image(image_paths[index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[index]\n",
    "    thresholds = [threshold_from_fpr(anomaly_map, fpr_level) for fpr_level in FRP_levels]\n",
    "    anomaly_map = anomaly_map.numpy()\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.imshow(anomaly_map, cmap=\"jet\", alpha=0.10, vmin=global_normal_vmin, vmax=global_normal_vmax)\n",
    "    c = ax.contour(anomaly_map, levels=thresholds, linewidths=1, colors=[\"blue\", \"yellow\", \"red\"])\n",
    "    ax.set_title(f\"image {index}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Anomaly maps colored in JET colormap with min-max normalization across all normal images. \"\n",
    "    \"     $\\\\operatorname{FPR}^{i}$ levels:   \"\n",
    "    f\"Blue = {fmt_pow10(FRP_levels[0])}  Yellow = {fmt_pow10(FRP_levels[1])}  Red = {fmt_pow10(FRP_levels[2])}\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Contours of $\\\\operatorname{FPR}^{i}$ levels on normal samples from the test set\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes about the different FPR levels:\n",
    "- $10^{-2}$ (blue): images have many and/or quite visible false positive regions;\n",
    "- $10^{-3}$ (yellow): most regions disappear, but a few are still visible; \n",
    "- $10^{-4}$ (red): usually one or two regions, barely visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Average FPR on Normal Images ($\\operatorname{FPRn}$)\n",
    "\n",
    "Let's now visualize the $\\operatorname{FPRn}$ and the variance of $\\operatorname{FPR}^{i}$ across the normal images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visalization of $FPRn$\n",
    "#    this one is an average behavior of the previous\n",
    "#    so one should expect a similar behavior but with\n",
    "#    some variations at each FPR level\n",
    "\n",
    "# we'll visualize the same FPR levels\n",
    "FRP_levels = [1e-2, 1e-3, 1e-4]\n",
    "# technical detail: decreasing order of FPR --> increasing order of threshold\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5.2), layout=\"constrained\")\n",
    "\n",
    "# function `threshold_from_fpr()` is replaced by an equivalent function\n",
    "# for FPRn is already implemented in `pimo_result.thresh_at`\n",
    "thresholds = [pimo_result.thresh_at(fpr_level)[1] for fpr_level in FRP_levels]\n",
    "# note that all images used the same (ie 'shared') thresholds now\n",
    "\n",
    "# `normal_images_selection` is the same from the previous cell\n",
    "for ax, index in zip(axes, normal_images_selection, strict=False):\n",
    "    image = cv2.resize(read_image(image_paths[index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[index]\n",
    "    fprs = [(anomaly_map > threshold).float().mean() for threshold in thresholds]\n",
    "    anomaly_map = anomaly_map.numpy()\n",
    "\n",
    "    ax.imshow(image)\n",
    "    # `global_normal_vmin` and `global_normal_vmax` are the same from the previous cell\n",
    "    ax.imshow(anomaly_map, cmap=\"jet\", alpha=0.10, vmin=global_normal_vmin, vmax=global_normal_vmax)\n",
    "    c = ax.contour(anomaly_map, levels=thresholds, linewidths=1, colors=[\"blue\", \"yellow\", \"red\"])\n",
    "    ax.set_title(f\"image {index}\")\n",
    "\n",
    "    ax.annotate(\n",
    "        \"$\\\\operatorname{FPR}^{i}$ levels: \"\n",
    "        f\"Blue = {fprs[0] * 100:.1g}%    Yellow = {fprs[1] * 100:.1g}%    Red = {fprs[2] * 100:.1g}%\",\n",
    "        xy=(0.01, 0.01),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Anomaly maps colored in JET colormap with min-max normalization across all normal images. \"\n",
    "    \"     $\\\\operatorname{FPRn}$ levels:   \"\n",
    "    f\"Blue = {fmt_pow10(FRP_levels[0])}    Yellow = {fmt_pow10(FRP_levels[1])}    Red = {fmt_pow10(FRP_levels[2])}\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Contours of $\\\\operatorname{FPRn}$ levels on normal samples from the test set\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "#### Variance\n",
    "\n",
    "Note that each $\\operatorname{FPR}^{i}$ has a wide variance\\* of visual results across images.\n",
    " \n",
    "For instance, the blue level ranges from 0.2% to 3%, which visually is a huge difference, and the red level doesn't even show in most images.\n",
    "\n",
    "This variance is specific to each model-dataset, we observed many state-of-the-art models on the datasets from MVTec-AD and VisA, and we noticed that low levels tend to have a negligible visual variance.\n",
    "\n",
    "#### Default bounds (L and U)\n",
    "\n",
    "So how were the default bounds chosen?\n",
    "\n",
    "> Recall: \n",
    "> \n",
    "> $$\n",
    ">     \\text{AUPIMO} \n",
    ">     \\; = \\; \n",
    ">     \\frac{1}{\\log(U/L)}\n",
    ">     \\int_{\\log(L)}^{\\log(U)} \n",
    ">     \\operatorname{TPR}^{i}\\left( \\operatorname{FRPn^{-1}}( z ) \\right)\n",
    ">     \\, \n",
    ">     \\mathrm{d}\\log(z)   \n",
    "> $$\n",
    "\n",
    "##### Upper bound U = 10^{-4}\n",
    "\n",
    "The upper bound $U$ sets the requirement level of the detection task.\n",
    "\n",
    "The lower the $U$, the harder the task, and ideally we'd like it be zero (i.e. anomalies are detected with no false positives).\n",
    "\n",
    "Compared to the images' content, the regions at $\\operatorname{FPRn} = 10^{-4}$ are _visually negligible_\\*.\n",
    " \n",
    "##### Lower bound L = 10^{-5}\n",
    "\n",
    "The lower bound $L$ has two numerical motivations.\n",
    "\n",
    "First, AUPIMO's integral is in log scale, so necessarily $L > 0$ and more weight is given to lower FPR levels.\n",
    "\n",
    "Second, images/masks/anomaly maps have finite resolution ($\\approx 10^{6}$ pixels/image\\*) -- so $\\operatorname{FPR}^{i}$ and $\\operatorname{FPRn}$ have discrete ranges.\n",
    "\n",
    "At $\\operatorname{FPRn} = 10^{-5}$, the discretization effects are still reasonable.\n",
    "\n",
    "##### Be careful!\n",
    "\n",
    "\\* These observations are based on the datasets we analyzed (from MVTec-AD and VisA).\n",
    "\n",
    "For other datasets, the default bounds may not be the best choice.\n",
    "\n",
    "Fortunately, AUPIMO allows customizing the bounds!\n",
    "\n",
    "> More details on these topics in our paper (see the last cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FPRn bounds\n",
    "\n",
    "It's very easy to customize the $\\operatorname{FPRn}$ bounds $L$ and $U$ in AUPIMO.\n",
    "\n",
    "You can guess from the signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPIMO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recompute the scores with the following situation: \n",
    "- $U = 10^{-2}$ to make the detection task easier;\n",
    "- $L = 10^{-4}$ assuming that \"small\" anomalies are not important for the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aupimo_custom = AUPIMO(\n",
    "    # with `False` all the values are returned in a dataclass\n",
    "    return_average=False,\n",
    "    # customized!\n",
    "    fpr_bounds=(1e-4, 1e-2),\n",
    ")\n",
    "\n",
    "for batch in predictions:\n",
    "    aupimo_custom.update(batch)\n",
    "pimo_result_custom, aupimo_result_custom = aupimo_custom.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 5), layout=\"tight\")\n",
    "\n",
    "for ax, index in zip(axes.flatten(), samples, strict=False):\n",
    "    score = aupimo_result_custom.aupimos[index].item()\n",
    "    tpr = pimo_result_custom.per_image_tprs[index]\n",
    "    fpr = pimo_result_custom.shared_fpr\n",
    "    lower_bound, upper_bound = aupimo_custom.fpr_bounds\n",
    "    threshs_auc_mask = (pimo_result_custom.thresholds > aupimo_result_custom.thresh_lower_bound) & (\n",
    "        pimo_result_custom.thresholds < aupimo_result_custom.thresh_upper_bound\n",
    "    )\n",
    "    fpr_in_auc = fpr[threshs_auc_mask]\n",
    "    tpr_in_auc = tpr[threshs_auc_mask]\n",
    "\n",
    "    plot_pimo_with_auc_zone(ax, tpr, fpr, lower_bound, upper_bound, fpr_in_auc, tpr_in_auc)\n",
    "    ax.set_title(f\"Image {index} ({score:.0%} AUPIMO)\")\n",
    "\n",
    "axes[-1, -1].axis(\"off\")\n",
    "axes[-1, -1].text(\n",
    "    -0.08,\n",
    "    0,\n",
    "    \"\"\"\n",
    "FPRn: Avg. [in-image] False Positive Rate (FPR)\n",
    "      on normal images only ('n').\n",
    "\n",
    "TPR: [in-image] True Positive Rate (TPR),\n",
    "     or Recall.\n",
    "\n",
    "Integration zone in light pink, and area\n",
    "under the curve (AUC) in purple.\n",
    "\n",
    "This area is normalized by the range size\n",
    "so that AUPIMO is in [0, 1].\n",
    "\"\"\",\n",
    "    ha=\"left\",\n",
    "    va=\"bottom\",\n",
    "    fontsize=\"x-small\",\n",
    "    color=\"dimgray\",\n",
    "    font=\"monospace\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"PIMO curves\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the AUPIMO score increased with the easier task :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cite Us\n",
    "\n",
    "AUPIMO was developed during Google Summer of Code 2023 (GSoC 2023) with the `anomalib` team from OpenVINO Toolkit.\n",
    "\n",
    "Our work was accepted to the British Machine Vision Conference 2024 (BMVC 2024).\n",
    "\n",
    "```bibtex\n",
    "@misc{bertoldo2024aupimo,\n",
    "      title={{AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed and Low Tolerance}}, \n",
    "      author={Joao P. C. Bertoldo and Dick Ameln and Ashwin Vaidya and Samet AkÃ§ay},\n",
    "      year={2024},\n",
    "      eprint={2401.01984},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV},\n",
    "      url={https://arxiv.org/abs/2401.01984}, \n",
    "}\n",
    "```\n",
    "\n",
    "Paper on arXiv: [arxiv.org/abs/2401.01984](https://arxiv.org/abs/2401.01984) (accepted to BMVC 2024)\n",
    "\n",
    "Medium post: [medium.com/p/c653ac30e802](https://medium.com/p/c653ac30e802)\n",
    "\n",
    "Official repository: [github.com/jpcbertoldo/aupimo](https://github.com/jpcbertoldo/aupimo) (numpy-only API and numba-accelerated versions available)\n",
    "\n",
    "GSoC 2023 page: [summerofcode.withgoogle.com/archive/2023/projects/SPMopugd](https://summerofcode.withgoogle.com/archive/2023/projects/SPMopugd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
