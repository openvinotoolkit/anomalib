{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ae5969",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "# Notebook Utils\n",
    "\n",
    "This notebook contains helper functions and classes for use with OpenVINOâ„¢ Notebooks. The code is synchronized with the `notebook_utils.py` file in the same directory as this notebook.\n",
    "\n",
    "There are five categories:\n",
    "\n",
    "- [Files](#Files)\n",
    "- [Images](#Images)\n",
    "- [Videos](#Videos)\n",
    "- [Visualization](#Visualization)\n",
    "- [OpenVINO Tools](#OpenVINO-Tools)\n",
    "- [Checks and Alerts](#Checks-and-Alerts)\n",
    "\n",
    "Each category contains a test cell that also shows how to use the functions in the section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b4817",
   "metadata": {},
   "source": [
    "## Files\n",
    "\n",
    "Load an image, download a file, download an OpenVINO IR model, and create a progress bar to show download progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6180e2b-171c-4a71-92c6-4c404a831d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from notebook_utils import load_image, download_file, download_ir_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99c45c-7649-4960-95dc-f2ea27f20950",
   "metadata": {},
   "outputs": [],
   "source": [
    "??load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f972d9-3b8c-4536-944a-62457c07c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "??download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3422bc-55f5-42c4-802b-e049ca45300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "??download_ir_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d4219",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Test File Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a0ee0",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "model_url = \"https://github.com/openvinotoolkit/openvino_notebooks/raw/main/notebooks/002-openvino-api/model/segmentation.xml\"\n",
    "download_ir_model(model_url, \"model\")\n",
    "\n",
    "assert os.path.exists(\"model/segmentation.xml\")\n",
    "assert os.path.exists(\"model/segmentation.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51392a8e",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/intel-iot-devkit/safety-gear-detector-python/raw/master/resources/Safety_Full_Hat_and_Vest.mp4\"\n",
    "if os.path.exists(os.path.basename(url)):\n",
    "    os.remove(os.path.basename(url))\n",
    "video_file = download_file(url)\n",
    "print(video_file)\n",
    "assert os.path.exists(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46478651",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/README.md\"\n",
    "filename = \"openvino_notebooks_readme.md\"\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "readme_file = download_file(url, filename=filename)\n",
    "print(readme_file)\n",
    "assert os.path.exists(readme_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15056b5",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/README.md\"\n",
    "filename = \"openvino_notebooks_readme.md\"\n",
    "directory = \"temp\"\n",
    "video_file = download_file(\n",
    "    url, filename=filename, directory=directory, show_progress=False, silent=True\n",
    ")\n",
    "print(readme_file)\n",
    "assert os.path.exists(readme_file)\n",
    "shutil.rmtree(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56466d-d62b-44ae-b68b-a3ce10ded5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/image/coco.jpg\"\n",
    "image = load_image(url)\n",
    "Image.fromarray(image[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5caa5",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45916c",
   "metadata": {},
   "source": [
    "### Convert Pixel Data\n",
    "\n",
    "Normalize image pixel values between 0 and 1, and convert images to `RGB` and `BGR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a2fc8-0c10-48b0-837b-469ef70958c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from notebook_utils import normalize_minmax, to_rgb, to_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "??normalize_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c1c35-0246-4a28-a46c-e8890f2a5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "??to_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02863abc-c64d-4636-92b0-4fbeeb282507",
   "metadata": {},
   "outputs": [],
   "source": [
    "??to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ec41b",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Test Data Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae28f4",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "test_array = np.random.randint(0, 255, (100, 100, 3))\n",
    "normalized_array = normalize_minmax(test_array)\n",
    "\n",
    "assert normalized_array.min() == 0\n",
    "assert normalized_array.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2922a67",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "bgr_array = np.ones((100, 100, 3), dtype=np.uint8)\n",
    "bgr_array[:, :, 0] = 0\n",
    "bgr_array[:, :, 1] = 1\n",
    "bgr_array[:, :, 2] = 2\n",
    "rgb_array = to_rgb(bgr_array)\n",
    "\n",
    "assert np.all(bgr_array[:, :, 0] == rgb_array[:, :, 2])\n",
    "\n",
    "bgr_array_converted = to_bgr(rgb_array)\n",
    "assert np.all(bgr_array_converted == bgr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27e37e",
   "metadata": {},
   "source": [
    "## Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134d512",
   "metadata": {},
   "source": [
    "### Video Player\n",
    "\n",
    "A custom video player to fulfill FPS requirements. You can set target FPS and output size, flip the video horizontally or skip first N frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a3145",
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import Image, clear_output, display\n",
    "from notebook_utils import VideoPlayer\n",
    "\n",
    "??VideoPlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab7b29e",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Test Video Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1fc3c",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "video = \"../data/video/Coco Walking in Berkeley.mp4\"\n",
    "\n",
    "player = VideoPlayer(video, fps=15, skip_first_frames=10)\n",
    "player.start()\n",
    "for i in range(50):\n",
    "    frame = player.next()\n",
    "    _, encoded_img = cv2.imencode(\".jpg\", frame, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "    img = Image(data=encoded_img)\n",
    "    clear_output(wait=True)\n",
    "    display(img)\n",
    "\n",
    "player.stop()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c69891",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67182f4f",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "Define a `SegmentationMap NamedTuple` that keeps the labels and colormap for a segmentation project/dataset. Create `CityScapesSegmentation` and `BinarySegmentation SegmentationMaps`. Create a function to convert a segmentation map to an `RGB` image with a `colormap`, and to show the segmentation result as an overlay over the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c64d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import SegmentationMap, CityScapesSegmentation, BinarySegmentation, segmentation_map_to_image, segmentation_map_to_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "??Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5e1a3-318b-411a-a69f-0e2588d2de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "??SegmentationMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce07cb-90fa-4ea1-ad31-00a19f5ececa",
   "metadata": {},
   "outputs": [],
   "source": [
    "??CityScapesSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad558a4-fdfb-49ef-a4f7-e981023272ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"cityscapes segmentation lables: \\n{CityScapesSegmentation.get_labels()}\")\n",
    "print(f\"cityscales segmentation colors: \\n{CityScapesSegmentation.get_colormap()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd01fc-a793-448d-8f72-dcd4a0f2084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "??BinarySegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d83cff-5975-470a-a08b-47647bef0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"binary segmentation lables: \\n{BinarySegmentation.get_labels()}\")\n",
    "print(f\"binary segmentation colors: \\n{BinarySegmentation.get_colormap()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef81db-8b4a-4fa3-9623-63542a52e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "??segmentation_map_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0b5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "??segmentation_map_to_overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab2c0c",
   "metadata": {},
   "source": [
    "### Network Results\n",
    "\n",
    "Show network result image, optionally together with the source image and a legend with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162edd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from notebook_utils import viz_result_image\n",
    "\n",
    "??viz_result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f109c8-1b31-44ce-9c8e-6e52dd489994",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Test Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d300c70",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "testimage = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "testimage[30:80, 30:80, :] = [0, 255, 0]\n",
    "testimage[0:10, 0:10, :] = 100\n",
    "testimage[40:60, 40:60, :] = 128\n",
    "testimage[testimage == 0] = 128\n",
    "\n",
    "\n",
    "testmask1 = np.zeros((testimage.shape[:2]))\n",
    "testmask1[30:80, 30:80] = 1\n",
    "testmask1[40:50, 40:50] = 0\n",
    "testmask1[0:15, 0:10] = 2\n",
    "\n",
    "result_image_overlay = segmentation_map_to_overlay(\n",
    "    image=testimage,\n",
    "    result=testmask1,\n",
    "    alpha=0.6,\n",
    "    colormap=np.array([[0, 0, 0], [255, 0, 0], [255, 255, 0]]),\n",
    ")\n",
    "result_image = segmentation_map_to_image(testmask1, CityScapesSegmentation.get_colormap())\n",
    "result_image_no_holes = segmentation_map_to_image(\n",
    "    testmask1, CityScapesSegmentation.get_colormap(), remove_holes=True\n",
    ")\n",
    "resized_result_image = cv2.resize(result_image, (50, 50))\n",
    "overlay_result_image = segmentation_map_to_overlay(\n",
    "    testimage, testmask1, 0.6, CityScapesSegmentation.get_colormap(), remove_holes=False\n",
    ")\n",
    "\n",
    "fig1 = viz_result_image(result_image, testimage)\n",
    "fig2 = viz_result_image(result_image_no_holes, testimage, labels=CityScapesSegmentation)\n",
    "fig3 = viz_result_image(\n",
    "    resized_result_image,\n",
    "    testimage,\n",
    "    source_title=\"Source Image\",\n",
    "    result_title=\"Resized Result Image\",\n",
    "    resize=True,\n",
    ")\n",
    "fig4 = viz_result_image(\n",
    "    overlay_result_image,\n",
    "    labels=CityScapesSegmentation,\n",
    "    result_title=\"Image with Result Overlay\",\n",
    ")\n",
    "\n",
    "display(fig1, fig2, fig3, fig4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97885ed0-8dea-4511-8558-bf146f5ae9d9",
   "metadata": {},
   "source": [
    "### Live Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf6f55-3d43-467b-94ed-318e345a4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import show_live_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dbdfe9-9311-491d-bece-19e9e5acd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "??show_live_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df4809-567b-4d3b-b947-d4a0ed981ce9",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "#### Test Live Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6be35b-de7b-47b7-8cd1-f6ef96e2d0cb",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Test binary segmentation\n",
    "from models.custom_segmentation import SegmentationModel\n",
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "\n",
    "image_paths = sorted(list(Path(\"../111-detection-quantization/data\").glob(\"*.jpg\")))\n",
    "\n",
    "ie = Core()\n",
    "segmentation_model = SegmentationModel(\n",
    "    ie,\n",
    "    Path(\"model/segmentation.xml\"),\n",
    "    sigmoid=False,\n",
    "    colormap=np.array([[0, 0, 0], [0, 0, 255]]),\n",
    "    rgb=True,\n",
    "    rotate_and_flip=False,\n",
    ")\n",
    "\n",
    "show_live_inference(\n",
    "    ie=ie,\n",
    "    image_paths=image_paths,\n",
    "    model=segmentation_model,\n",
    "    device=\"CPU\",\n",
    "    reader=lambda x: cv2.cvtColor(cv2.imread(x), cv2.COLOR_BGR2RGB),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b9127-74b5-4172-8104-5aacf6a22b9c",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Test multiclass segmentation with different input shape.\n",
    "# This requires running the 102 notebook first, to generate the Fastseg model.\n",
    "\n",
    "fastseg_path = Path(\"../102-pytorch-onnx-to-openvino/model/fastseg1024.xml\")\n",
    "image_path = \"../data/image/street.jpg\"\n",
    "\n",
    "if fastseg_path.exists():\n",
    "    image_paths = [\n",
    "        image_path,\n",
    "    ] * 5\n",
    "\n",
    "    ie = Core()\n",
    "    CityScapesSegmentation = SegmentationMap(cityscape_labels)\n",
    "    segmentation_model = SegmentationModel(\n",
    "        ie,\n",
    "        fastseg_path,\n",
    "        sigmoid=False,\n",
    "        argmax=True,\n",
    "        colormap=CityScapesSegmentation.get_colormap(),\n",
    "        rgb=True,\n",
    "    )\n",
    "    show_live_inference(ie=ie, image_paths=image_paths, model=segmentation_model, device=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46431fa9",
   "metadata": {},
   "source": [
    "## Checks and Alerts\n",
    "\n",
    "Create an alert class to show stylized info/error/warning messages and a `check_device` function that checks whether a given device is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bd4a7-fa1b-41aa-9116-287361780f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import NotebookAlert, DeviceNotFoundAlert, check_device, check_openvino_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ccdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "??NotebookAlert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a76f3e-69c9-46c3-a75b-8a6f04c92f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "??DeviceNotFoundAlert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf8ad9-6a65-4359-b32b-c38d347bfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "??check_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a8304-03df-4c37-bd2e-55623e88e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "??check_openvino_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e1d08",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Test Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7983c8f",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "NotebookAlert(message=\"Hello, world!\", alert_class=\"info\")\n",
    "DeviceNotFoundAlert(\"GPU\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda8ef3",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "assert check_device(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944820e1",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "if check_device(\"HELLOWORLD\"):\n",
    "    print(\"Hello World device found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c370ef",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "check_openvino_version(\"2022.1\");"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
