{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92448b5a",
   "metadata": {},
   "source": [
    "# Simulation of production line with defects - Dataset creation and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037882b",
   "metadata": {},
   "source": [
    "_This notebook is originally created by [@paularamos](https://github.com/paularamo) for CVPR-2022 Tutorial [How to get quick and performant model for your edge application. From data to application](https://paularamo.github.io/cvpr-2022/)_\n",
    "\n",
    "### Definitions\n",
    "\n",
    "[Anomalib](https://github.com/openvinotoolkit/anomalib): Anomalib is a deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets. Anomalib provides several ready-to-use implementations of anomaly detection algorithms described in the recent literature, as well as a set of tools that facilitate the development and implementation of custom models. The library has a strong focus on image-based anomaly detection, where the goal of the algorithm is to identify anomalous images, or anomalous pixel regions within images in a dataset.\n",
    "\n",
    "[Dobot](https://en.dobot.cn/products/education/magician.html) The Magician is an education robot arm portable and capable to run various automation tasks. With an interface in C++ and python we can control the robot using this notebook. \n",
    "\n",
    "> NOTE: \n",
    "If you don't have the robot you can replace it by your custome problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdde70",
   "metadata": {},
   "source": [
    "### Use case\n",
    "\n",
    "Using the [Dobot Magician](https://www.dobot.cc/dobot-magician/product-overview.html) we could simulate a production line system. Imagine we have a cubes factory and they need to know when a defect piece appear in the process. We know very well what is the aspecto of the normal cubes. Defects are coming no often and we need to put those defect cubes out of the production line.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/10940214/174126337-b344bbdc-6343-4d85-93e8-0cb1bf39a4e3.png\" alt=\"drawing\" style=\"width:400px;\"/>\n",
    "\n",
    "\n",
    "| Class | Yellow cube | Red cube | Green cube | Inferencing using Anomalib\n",
    "| --------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ | --------------------------------------------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| Normal | <img src=\"https://user-images.githubusercontent.com/10940214/174083561-38eec918-efc2-4ceb-99b1-bbb4c91396b2.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083638-85ff889c-6222-4428-9c7d-9ad62bd15afe.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083707-364177d4-373b-4891-96ce-3e5ea923e440.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174129305-03d9b71c-dfd9-492f-b42e-01c5c24171cc.jpg\" alt=\"drawing\" style=\"width:150px;\"/> |\n",
    "| Abnormal | <img src=\"https://user-images.githubusercontent.com/10940214/174083805-df0a0b03-58c7-4ba8-af50-fd94d3a13e58.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083873-22699523-22b4-4a55-a3da-6520095af8af.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174083944-38d5a6f4-f647-455b-ba4e-69482dfa3562.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | <img src=\"https://user-images.githubusercontent.com/10940214/174129253-f7a567d0-84f7-4050-8065-f00ba8bb973d.jpg\" alt=\"drawing\" style=\"width:150px;\"/> | \n",
    "\n",
    "Using Anomalib we are expecting to see this result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ea1ae",
   "metadata": {},
   "source": [
    "### Import packages for Anomalib and Dobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc20e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomalib imports\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.config import get_configurable_parameters\n",
    "from anomalib.data import get_datamodule\n",
    "from anomalib.models import get_model\n",
    "from anomalib.pre_processing.transforms import Denormalize\n",
    "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
    "\n",
    "# Dobot/general imports\n",
    "import threading\n",
    "import DobotDllType as dType # comment this line if you don't have the Dobot Magician\n",
    "import cv2\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils #for using video encoder in the jupyter notebook\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2ea39",
   "metadata": {},
   "source": [
    "### Helper funtions\n",
    "\n",
    "Here you will find funtions to create filenames, capture images, run the inference and read the confidence of the detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa3bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filename_fc(acquisition: bool, folder: str, dataset_path: str): -> str\n",
    "    \"\"\"\n",
    "    Create the filename for new data(images) or \n",
    "    the filename for inference result image\n",
    "\n",
    "    :param: acquisition: mode True: acquire new data, \n",
    "                         False: run the inference\n",
    "            folder: directory to save the new images in \n",
    "                    acquisition mode (abnormal or normal) \n",
    "            dataset_path: Initial path to save new images and results\n",
    "    :returns:\n",
    "            filename: captured image filename\n",
    "            resultname: heatmap after inference filename\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    print(acquisition)\n",
    "    print(folder)\n",
    "    if not acquisition:\n",
    "        print(\"In inference mode we cannot use this function\")\n",
    "        filename = None #Path(f\"{dataset_path}/testing/inferencing_\") + str(now.strftime(\"%Y%m%d%H%M%S\")) + \".jpg\"\n",
    "        return filename \n",
    "    \n",
    "    if folder == \"abnormal\":\n",
    "        filename = Path(f\"{dataset_path}/train/anormal/input_\" + str(now.strftime(\"%Y%m%d%H%M%S\")) + \".jpg\"\n",
    "    elif folder == \"normal\":\n",
    "        filename = Path(f\"{dataset_path}/train/normal/input_\" + str(now.strftime(\"%Y%m%d%H%M%S\")) + \".jpg\"\n",
    "    print(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c7eab",
   "metadata": {},
   "source": [
    "### Prepare the mode (acquisition or inference mode) and define the work directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the path to save the new image and the anomalib results\n",
    "dataset_path = \"C:/Anomalib/datasets/cubes\"\n",
    "# Acquisiton mode\n",
    "acquisition = False #True False\n",
    "# Normal or abnormal batch\n",
    "folder = \"normal\" #abnormal normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968a85",
   "metadata": {},
   "source": [
    "### Define some functions for using a webcam in real time\n",
    "\n",
    "Using multi-threading we will open the video to auto-capture an image when the robot locates the cube in front of the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame():\n",
    "    global frame, input_image\n",
    "    while True:\n",
    "        frame = player.next()\n",
    "        if frame is None:\n",
    "            print(\"Source ended\")\n",
    "            break\n",
    "        # If the frame is larger than full HD, reduce size to improve the performance.\n",
    "        scale = 1280 / max(frame.shape)\n",
    "        if scale < 1:\n",
    "            frame = cv2.resize(\n",
    "                src=frame,\n",
    "                dsize=None,\n",
    "                fx=scale,\n",
    "                fy=scale,\n",
    "                interpolation=cv2.INTER_AREA,\n",
    "            )\n",
    "        # Get the results.\n",
    "        input_image = np.array(frame)\n",
    "\n",
    "def anomalib_inference(use_popup):\n",
    "    global predictions\n",
    "    while True:\n",
    "        predictions = inferencer.predict(image=frame)\n",
    "        if use_popup:\n",
    "                cv2.imshow(winname=title2, mat=predictions.heat_map)\n",
    "                key = cv2.waitKey(1)\n",
    "                # esc = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                # Encode numpy array to jpg.\n",
    "                _, encoded_img2 = cv2.imencode(\n",
    "                    ext=\".jpg\", img=predictions.heat_map, params=[cv2.IMWRITE_JPEG_QUALITY, 100]\n",
    "                )\n",
    "                # Create an IPython image.\n",
    "                i2 = display.Image(data=encoded_img2)\n",
    "                # Display the image in this notebook.\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i2)\n",
    "    \n",
    "def create_dataset():\n",
    "    while True:\n",
    "        showPic = cv2.imwrite(filename,frame)\n",
    "    \n",
    "def realtime(use_popup):\n",
    "    while True:\n",
    "        if use_popup:\n",
    "                cv2.imshow(winname=title, mat=frame)\n",
    "                key = cv2.waitKey(1)\n",
    "                # esc = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                # Encode numpy array to jpg.\n",
    "                _, encoded_img = cv2.imencode(\n",
    "                    ext=\".jpg\", img=frame, params=[cv2.IMWRITE_JPEG_QUALITY, 100]\n",
    "                )\n",
    "                # Create an IPython image.\n",
    "                i = display.Image(data=encoded_img)\n",
    "                # Display the image in this notebook.\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62854abc",
   "metadata": {},
   "source": [
    "### Using a webcam or a USB camera for running the inference\n",
    "\n",
    "Connect and identify your US camera, we will use a a video player to embed the video in this notebook. \n",
    "\n",
    "> NOTE: \n",
    "If you don't have the robot you can replace it by your custom problem. See the comments below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a5943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CON_STR = {\n",
    "    dType.DobotConnect.DobotConnect_NoError:  \"DobotConnect_NoError\",\n",
    "    dType.DobotConnect.DobotConnect_NotFound: \"DobotConnect_NotFound\",\n",
    "    dType.DobotConnect.DobotConnect_Occupied: \"DobotConnect_Occupied\"}\n",
    "\n",
    "#Load Dll and get the CDLL object\n",
    "api = dType.load()\n",
    "\n",
    "#Connect Dobot\n",
    "state = dType.ConnectDobot(api, \"\", 115200)[0]\n",
    "print(\"Connect status:\",CON_STR[state])\n",
    "\n",
    "use_popup = False #True\n",
    "\n",
    "if (state == dType.DobotConnect.DobotConnect_NoError):\n",
    "\n",
    "    Calibration__0__Run__1 = None\n",
    "    Calibration_X = None\n",
    "    Calibration_Y = None\n",
    "    Calibration_Z = None\n",
    "    Place_X = None\n",
    "    Place_Y = None\n",
    "    Place_Z = None\n",
    "    Anomaly_X = None\n",
    "    Anomaly_Y = None\n",
    "    Anomaly_Z = None\n",
    "    j = None\n",
    "    k = None\n",
    "    time_start = None\n",
    "  \n",
    "    print('[HOME] Restore to home position at first launch, please wait 30 seconds after turnning on the Dobot Magician.')\n",
    "    print('[BLOCKS] Place them besides the non-motor side of the conveyor belt, the same side where the pick and place arm is.')\n",
    "    print('[PLACING BLOCKS] Place the blocks by 3Ã—3.')\n",
    "    print('[CALIBRATION POINT] Looking from the back of Dobot, the top left block is the calibration point.')\n",
    "    print('[CALIBRATION] Set the first variable to 0 to test the calibration point, then set 1 to start running.')\n",
    "    print('[DIRECTION] Standing behind Dobot Magician facing its front direction, X is front and back direction, Y is left and right direction. ')\n",
    "    print('[CONNECTION] Motor of the conveyor belt connects to port Stepper1.')\n",
    "    \n",
    "    Calibration__0__Run__1 = 1\n",
    "    Calibration_X = 221.2288\n",
    "    Calibration_Y = -117.0036\n",
    "    Calibration_Z = -42.3512\n",
    "    Place_X = 23.7489 #42.2995 #\n",
    "    Place_Y = -264.2602 #-264.6927 #\n",
    "    Place_Z = 18.0862 #63.65 #\n",
    "    Anomaly_X = -112 #-84.287 #\n",
    "    Anomaly_Y = -170 #-170.454 #\n",
    "    Anomaly_Z = 90 #61.5359 #\n",
    "    dType.SetEndEffectorParamsEx(api, 59.7, 0, 0, 1)\n",
    "    j = 0\n",
    "    k = 0\n",
    "    dType.SetPTPJointParamsEx(api,400,400,400,400,400,400,400,400,1)\n",
    "    dType.SetPTPCommonParamsEx(api,100,100,1)\n",
    "    dType.SetPTPJumpParamsEx(api,40,100,1)\n",
    "    dType.SetPTPCmdEx(api, 0, Calibration_X,  Calibration_Y,  Calibration_Z, 0, 1)\n",
    "    dType.SetEndEffectorSuctionCupEx(api, 0, 1)\n",
    "    STEP_PER_CRICLE = 360.0 / 1.8 * 10.0 * 16.0\n",
    "    MM_PER_CRICLE = 3.1415926535898 * 36.0\n",
    "    vel = float(0) * STEP_PER_CRICLE / MM_PER_CRICLE\n",
    "    dType.SetEMotorEx(api, 1, 0, int(vel), 1)\n",
    "    if Calibration__0__Run__1:\n",
    "        player = None\n",
    "        # Create a video player to play with target fps.\n",
    "        player = utils.VideoPlayer(source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
    "        # Start capturing.\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit - Original\"\n",
    "            title2 = \"Press ESC to Exit - Inference\"\n",
    "            cv2.namedWindow(\n",
    "                winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE\n",
    "            )\n",
    "            cv2.namedWindow(\n",
    "                winname=title2, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE\n",
    "            )\n",
    "\n",
    "        for count in range(9):\n",
    "            dType.SetPTPCmdEx(api, 0, (Calibration_X - j),  (Calibration_Y - k),  (Calibration_Z - 10), 0, 1)\n",
    "            dType.SetEndEffectorSuctionCupEx(api, 1, 1)\n",
    "            #dType.dSleep(150)\n",
    "            dType.SetPTPCmdEx(api, 0, (Place_X - 0),  (Place_Y - 0),  (Place_Z + 90), 0, 1)\n",
    "            filename, resultname = filename_fc(acquisition, folder)\n",
    "            ### Capture a frame from the video player - start thread\n",
    "            gfthread = threading.Thread(target=getFrame, args='')\n",
    "            gfthread.daemon = True\n",
    "            gfthread.start()\n",
    "            ### Display the video\n",
    "            rtthread = threading.Thread(target=realtime(), args=(use_popup,))\n",
    "            rtthread.daemon = True\n",
    "            rtthread.start()\n",
    "            if not(acquisition):\n",
    "                # Get the inference results.\n",
    "                aithread = threading.Thread(target=anomalib_inference, args=(use_popup,))\n",
    "                aithread.daemon = True\n",
    "                aithread.start()\n",
    "                score = predictions.pred_score\n",
    "                ###################################\n",
    "                if score > 0.34:\n",
    "                    dType.SetPTPCmdEx(api, 0, Anomaly_X,  Anomaly_Y,  Anomaly_Z, 0, 1) ### define point for abnormalities\n",
    "                else:\n",
    "                    dType.SetPTPCmdEx(api, 0, Place_X,  Place_Y,  Place_Z, 0, 1)\n",
    "\n",
    "            if acquisition:\n",
    "                filename = filename_fc(acquisition, folder, dataset_path)\n",
    "                ### Create the dataset\n",
    "                cdthread = threading.Thread(target=create_dataset(filename), args='')\n",
    "                cdthread.daemon = True\n",
    "                cdthread.start()\n",
    "                dType.SetPTPCmdEx(api, 0, Place_X,  Place_Y,  Place_Z, 0, 1)\n",
    "                \n",
    "                #print(\"continue in the conveyor belt\")\n",
    "\n",
    "            dType.SetEndEffectorSuctionCupEx(api, 0, 1)\n",
    "            #dType.dSleep(150)\n",
    "            j = j + 25\n",
    "            if j == 75:\n",
    "                k = k + 25\n",
    "                j = 0\n",
    "            dType.SetPTPCmdEx(api, 7, 0,  0,  20, 0, 1)\n",
    "            time_start = dType.gettime()[0]\n",
    "            STEP_PER_CRICLE = 360.0 / 1.8 * 10.0 * 16.0\n",
    "            MM_PER_CRICLE = 3.1415926535898 * 36.0\n",
    "            vel = float(50) * STEP_PER_CRICLE / MM_PER_CRICLE\n",
    "            dType.SetEMotorEx(api, 1, 1, int(vel), 1)\n",
    "            filename = None\n",
    "            score = 0\n",
    "            while True:\n",
    "                if (dType.gettime()[0]) - time_start >= 0.5 : # Time over conveyor belt\n",
    "                    STEP_PER_CRICLE = 360.0 / 1.8 * 10.0 * 16.0\n",
    "                    MM_PER_CRICLE = 3.1415926535898 * 36.0\n",
    "                    vel = float(0) * STEP_PER_CRICLE / MM_PER_CRICLE\n",
    "                    dType.SetEMotorEx(api, 1, 0, int(vel), 1)\n",
    "                    break\n",
    "        dType.SetEndEffectorSuctionCupEx(api, 0, 1)\n",
    "        dType.SetPTPCmdEx(api, 0, Calibration_X,  Calibration_Y,  Calibration_Z, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aab3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -VV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bb666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
